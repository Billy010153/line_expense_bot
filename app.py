
import os
from flask import Flask, request, jsonify
from linebot import LineBotApi, WebhookParser
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from google_helper import append_expense, get_summary, get_recent_expenses_for_gpt
from openai import OpenAI

app = Flask(__name__)

LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_ACCESS_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
parser = WebhookParser(LINE_CHANNEL_SECRET)
client = OpenAI(api_key=OPENAI_API_KEY)

@app.route("/", methods=["GET"])
def home():
    return "è¨˜å¸³ + GPT è‡ªå‹•åˆ†é¡å•Ÿå‹•ä¸­"

@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers["X-Line-Signature"]
    body = request.get_data(as_text=True)

    try:
        events = parser.parse(body, signature)
    except:
        return "Invalid signature", 400

    for event in events:
        if isinstance(event, MessageEvent) and isinstance(event.message, TextMessage):
            user_text = event.message.text.strip()
            reply_text = handle_user_message(user_text)
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=reply_text)
            )

    return jsonify({"status": "ok"})

def auto_classify_item(item_name):
    prompt = f"è«‹å¹«æˆ‘åˆ¤æ–·ã€Œ{item_name}ã€å±¬æ–¼å“ªä¸€é¡æ¶ˆè²»ï¼Œåªå›å‚³åˆ†é¡åç¨±ï¼Œä¸è¦å¤šé¤˜æ–‡å­—ã€‚åˆ†é¡ä¾‹å¦‚ï¼šé¤é£²ã€äº¤é€šã€å¨›æ¨‚ã€æ—¥ç”¨å“ã€æ”¶å…¥ã€å…¶ä»–ã€‚"
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹è¨˜å¸³æ©Ÿå™¨äººï¼Œæ“…é•·å¹«ä½¿ç”¨è€…æ¨™è¨˜åˆ†é¡"},
        {"role": "user", "content": prompt}
    ]
    response = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages)
    return response.choices[0].message.content.strip()

def handle_user_message(msg):
    if msg.lower() in ["é¤˜é¡", "æŸ¥å¸³", "ç¸½è¦½"]:
        return get_summary()
    elif msg.startswith("/ai"):
        question = msg.replace("/ai", "").strip()
        if not question:
            return "è«‹è¼¸å…¥å•é¡Œï¼Œä¾‹å¦‚ï¼š/ai æˆ‘é€™é€±èŠ±äº†å¤šå°‘éŒ¢ï¼Ÿ"
        try:
            data = get_recent_expenses_for_gpt()
            messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è¨˜å¸³åˆ†æå¸«ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…æœ€è¿‘çš„æ”¯å‡ºè³‡æ–™ï¼Œä»¥è¦ªåˆ‡è‡ªç„¶çš„èªæ°£å›ç­”å•é¡Œã€‚"},
    {"role": "user", "content": f"é€™æ˜¯æœ€è¿‘çš„è¨˜å¸³ç´€éŒ„ï¼š\n{data}\n\n{question}"}
]
            response = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages)
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"â— GPT æŸ¥è©¢éŒ¯èª¤ï¼š{str(e)}"
            print(f"ğŸ“© å˜—è©¦å¯«å…¥ï¼š{msg}")
    try:
    print(f"ğŸ“© å˜—è©¦å¯«å…¥ï¼š{msg}")
    parts = msg.split()
    amount = float(parts[-1])
    item = parts[0]
    category = auto_classify_item(item)

    append_expense(item, amount, category)
    return f"{item} èŠ±è²» {amount} åˆ†é¡ï¼š{category}"
    print("ğŸ“ æ­£åœ¨å‘¼å« append_expense()")

except Exception as e:
    print(f"âŒ æ ¼å¼éŒ¯èª¤æˆ–å¯«å…¥å¤±æ•—ï¼š{str(e)}")
    return "âŒ æ ¼å¼éŒ¯èª¤ï¼è«‹ç”¨ å“é … é‡‘é¡ æ–¹å¼ï¼Œä¾‹å¦‚ï¼šæ—©é¤ 50"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
